<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yash Shah - AI Engineer & Voice Assistant Developer</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap');
        
        :root {
            --primary: #00f0ff;
            --primary-glow: rgba(0, 240, 255, 0.4);
            --secondary: #7b2cbf;
            --accent: #ff006e;
            --bg-dark: #0a0a0f;
            --bg-darker: #05050a;
            --bg-card: rgba(255, 255, 255, 0.03);
            --text: #ffffff;
            --text-muted: #a0a0b0;
            --border: rgba(255, 255, 255, 0.1);
            --glass-bg: rgba(255, 255, 255, 0.05);
            --glass-border: rgba(255, 255, 255, 0.15);
        }

        [data-theme="light"] {
            --primary: #0066ff;
            --primary-glow: rgba(0, 102, 255, 0.3);
            --secondary: #7b2cbf;
            --accent: #ff006e;
            --bg-dark: #f8f9fa;
            --bg-darker: #ffffff;
            --bg-card: rgba(0, 0, 0, 0.02);
            --text: #1a1a1a;
            --text-muted: #666666;
            --border: rgba(0, 0, 0, 0.1);
            --glass-bg: rgba(0, 0, 0, 0.02);
            --glass-border: rgba(0, 0, 0, 0.1);
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-darker);
            color: var(--text);
            overflow-x: hidden;
            line-height: 1.6;
            transition: background 0.3s ease, color 0.3s ease;
        }

        /* Advanced Background with Mesh Gradient */
        .bg-mesh {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
            background: 
                radial-gradient(at 20% 30%, var(--secondary) 0px, transparent 50%),
                radial-gradient(at 80% 70%, var(--accent) 0px, transparent 50%),
                radial-gradient(at 50% 50%, var(--primary) 0px, transparent 50%),
                var(--bg-darker);
            filter: blur(100px);
            opacity: 0.3;
            animation: meshMove 15s ease infinite;
        }

        @keyframes meshMove {
            0%, 100% { transform: scale(1) rotate(0deg); }
            50% { transform: scale(1.1) rotate(5deg); }
        }

        /* Glassmorphism Navigation */
        nav {
            position: fixed;
            top: 2rem;
            left: 50%;
            transform: translateX(-50%);
            z-index: 1000;
            background: var(--glass-bg);
            backdrop-filter: blur(20px);
            border: 1px solid var(--glass-border);
            border-radius: 100px;
            padding: 0.8rem 2rem;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.2);
        }

        .nav-content {
            display: flex;
            align-items: center;
            gap: 3rem;
        }

        .logo {
            font-size: 1.3rem;
            font-weight: 800;
            background: linear-gradient(135deg, var(--primary), var(--accent));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .nav-links {
            display: flex;
            gap: 2rem;
            list-style: none;
        }

        .nav-links a {
            color: var(--text);
            text-decoration: none;
            font-weight: 500;
            font-size: 0.95rem;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            padding: 0.5rem 1rem;
        }

        .nav-links a::before {
            content: '';
            position: absolute;
            bottom: 0;
            left: 50%;
            width: 0;
            height: 2px;
            background: linear-gradient(90deg, var(--primary), var(--accent));
            transform: translateX(-50%);
            transition: width 0.3s ease;
        }

        .nav-links a:hover::before {
            width: 80%;
        }

        .theme-toggle-btn {
            background: var(--glass-bg);
            border: 1px solid var(--glass-border);
            border-radius: 50px;
            padding: 0.5rem 1rem;
            color: var(--text);
            cursor: pointer;
            font-size: 1.1rem;
            transition: all 0.3s ease;
        }

        .theme-toggle-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 12px var(--primary-glow);
        }

        /* Hero Section with 3D Card */
        .landing {
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 8rem 5% 5rem;
            position: relative;
        }

        .hero-3d-card {
            perspective: 1500px;
            max-width: 1200px;
            width: 100%;
        }

        .card-inner {
            position: relative;
            transform-style: preserve-3d;
            transition: transform 0.8s cubic-bezier(0.4, 0, 0.2, 1);
        }

        .hero-content {
            position: relative;
            background: var(--glass-bg);
            backdrop-filter: blur(20px);
            border: 1px solid var(--glass-border);
            border-radius: 30px;
            padding: 5rem 4rem;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }

        .hero-badge {
            display: inline-block;
            background: linear-gradient(135deg, var(--primary), var(--accent));
            color: var(--bg-dark);
            padding: 0.6rem 1.5rem;
            border-radius: 50px;
            font-weight: 600;
            font-size: 0.9rem;
            margin-bottom: 2rem;
            animation: fadeSlideDown 1s ease;
        }

        @keyframes fadeSlideDown {
            from { opacity: 0; transform: translateY(-20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .hero-title {
            font-size: clamp(3rem, 8vw, 5.5rem);
            font-weight: 800;
            line-height: 1.1;
            margin-bottom: 1.5rem;
            background: linear-gradient(135deg, var(--text), var(--primary));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            animation: fadeSlideUp 1s 0.2s ease backwards;
        }

        @keyframes fadeSlideUp {
            from { opacity: 0; transform: translateY(30px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .typing-container {
            min-height: 3rem;
            margin-bottom: 2rem;
            animation: fadeSlideUp 1s 0.4s ease backwards;
        }

        .hero-subtitle {
            font-size: clamp(1.5rem, 3vw, 2rem);
            color: var(--primary);
            font-weight: 600;
            display: inline-block;
        }

        .typing-cursor {
            display: inline-block;
            width: 3px;
            height: 1.8rem;
            background: var(--primary);
            margin-left: 0.3rem;
            animation: blink 1s step-end infinite;
        }

        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0; }
        }

        .hero-description {
            font-size: 1.2rem;
            color: var(--text-muted);
            line-height: 1.8;
            margin-bottom: 3rem;
            max-width: 700px;
            animation: fadeSlideUp 1s 0.6s ease backwards;
        }

        .cta-group {
            display: flex;
            gap: 1.5rem;
            flex-wrap: wrap;
            animation: fadeSlideUp 1s 0.8s ease backwards;
        }

        .btn-primary, .btn-secondary {
            padding: 1.2rem 2.5rem;
            border-radius: 50px;
            font-weight: 600;
            font-size: 1.05rem;
            cursor: pointer;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            border: none;
            text-decoration: none;
            display: inline-block;
        }

        .btn-primary {
            background: linear-gradient(135deg, var(--primary), var(--accent));
            color: var(--bg-dark);
            box-shadow: 0 4px 20px var(--primary-glow);
        }

        .btn-primary:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 30px var(--primary-glow);
        }

        .btn-secondary {
            background: transparent;
            color: var(--text);
            border: 2px solid var(--primary);
        }

        .btn-secondary:hover {
            background: var(--primary);
            color: var(--bg-dark);
            transform: translateY(-3px);
        }

        /* Floating Tech Icons */
        .floating-icons {
            position: absolute;
            width: 100%;
            height: 100%;
            top: 0;
            left: 0;
            pointer-events: none;
        }

        .tech-icon {
            position: absolute;
            font-size: 3rem;
            opacity: 0.15;
            animation: floatIcon 4s ease-in-out infinite;
            filter: drop-shadow(0 0 10px var(--primary));
        }

        @keyframes floatIcon {
            0%, 100% { transform: translateY(0) rotate(0deg); }
            50% { transform: translateY(-30px) rotate(10deg); }
        }

        .tech-icon:nth-child(1) { top: 10%; left: 5%; animation-delay: 0s; }
        .tech-icon:nth-child(2) { top: 15%; right: 8%; animation-delay: 0.5s; }
        .tech-icon:nth-child(3) { bottom: 20%; left: 10%; animation-delay: 1s; }
        .tech-icon:nth-child(4) { bottom: 15%; right: 12%; animation-delay: 1.5s; }
        .tech-icon:nth-child(5) { top: 50%; left: 3%; animation-delay: 2s; }
        .tech-icon:nth-child(6) { top: 45%; right: 5%; animation-delay: 2.5s; }

        /* Dashboard Section with Bento Grid */
        .dashboard {
            min-height: 100vh;
            padding: 10rem 5% 5rem;
            display: none;
        }

        .dashboard.active { display: block; }

        .section-header {
            text-align: center;
            margin-bottom: 5rem;
        }

        .section-title {
            font-size: clamp(2.5rem, 5vw, 4rem);
            font-weight: 800;
            background: linear-gradient(135deg, var(--text), var(--primary));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 1rem;
        }

        .section-subtitle {
            font-size: 1.2rem;
            color: var(--text-muted);
        }

        /* Bento Grid Layout */
        .bento-grid {
            display: grid;
            grid-template-columns: repeat(12, 1fr);
            gap: 1.5rem;
            margin-bottom: 5rem;
        }

        .bento-item {
            background: var(--glass-bg);
            backdrop-filter: blur(20px);
            border: 1px solid var(--glass-border);
            border-radius: 25px;
            padding: 2.5rem;
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
            cursor: pointer;
        }

        .bento-item::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: radial-gradient(circle at var(--mouse-x, 50%) var(--mouse-y, 50%), var(--primary-glow), transparent 60%);
            opacity: 0;
            transition: opacity 0.3s;
        }

        .bento-item:hover::before {
            opacity: 1;
        }

        .bento-item:hover {
            transform: translateY(-8px);
            border-color: var(--primary);
            box-shadow: 0 20px 40px var(--primary-glow);
        }

        .bento-large {
            grid-column: span 6;
            grid-row: span 2;
        }

        .bento-medium {
            grid-column: span 6;
        }

        .bento-small {
            grid-column: span 4;
        }

        .project-icon {
            font-size: 3.5rem;
            margin-bottom: 1.5rem;
            filter: drop-shadow(0 0 20px var(--primary));
        }

        .project-tag {
            display: inline-block;
            background: var(--primary);
            color: var(--bg-dark);
            padding: 0.4rem 1rem;
            border-radius: 50px;
            font-size: 0.85rem;
            font-weight: 600;
            margin-bottom: 1rem;
        }

        .project-title {
            font-size: 1.8rem;
            font-weight: 700;
            margin-bottom: 1rem;
            color: var(--text);
        }

        .project-description {
            color: var(--text-muted);
            line-height: 1.7;
            margin-bottom: 1.5rem;
        }

        .project-tech-stack {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-bottom: 1.5rem;
        }

        .tech-badge {
            background: var(--glass-bg);
            border: 1px solid var(--border);
            padding: 0.4rem 1rem;
            border-radius: 20px;
            font-size: 0.85rem;
            color: var(--text-muted);
        }

        .project-link {
            color: var(--primary);
            text-decoration: none;
            font-weight: 600;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            transition: gap 0.3s ease;
        }

        .project-link:hover {
            gap: 1rem;
        }

        /* Voice Assistant Section - Enhanced */
        .voice-section {
            min-height: 100vh;
            padding: 10rem 5% 5rem;
            display: none;
        }

        .voice-section.active { display: flex; flex-direction: column; align-items: center; }

        .voice-container {
            max-width: 900px;
            width: 100%;
            background: var(--glass-bg);
            backdrop-filter: blur(20px);
            border: 1px solid var(--glass-border);
            border-radius: 30px;
            padding: 3rem;
            margin-top: 3rem;
        }

        .voice-visualizer {
            width: 250px;
            height: 250px;
            margin: 0 auto 2rem;
            position: relative;
        }

        .voice-orb {
            width: 100%;
            height: 100%;
            border-radius: 50%;
            background: radial-gradient(circle at 30% 30%, var(--primary), var(--accent));
            box-shadow: 0 0 60px var(--primary-glow);
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
        }

        .voice-orb:hover {
            transform: scale(1.08);
            box-shadow: 0 0 100px var(--primary-glow);
        }

        .voice-orb.listening {
            animation: voicePulse 1.5s ease-in-out infinite;
        }

        @keyframes voicePulse {
            0%, 100% {
                transform: scale(1);
                box-shadow: 0 0 60px var(--primary-glow);
            }
            50% {
                transform: scale(1.15);
                box-shadow: 0 0 120px var(--primary-glow);
            }
        }

        .voice-icon {
            font-size: 5rem;
            filter: drop-shadow(0 0 20px rgba(0,0,0,0.5));
        }

        .voice-waves {
            position: absolute;
            width: 100%;
            height: 100%;
            border-radius: 50%;
            border: 3px solid var(--primary);
            opacity: 0;
            animation: waveExpand 2s ease-out infinite;
        }

        .voice-waves:nth-child(2) { animation-delay: 0.5s; }
        .voice-waves:nth-child(3) { animation-delay: 1s; }

        @keyframes waveExpand {
            0% {
                transform: scale(1);
                opacity: 0.8;
            }
            100% {
                transform: scale(1.8);
                opacity: 0;
            }
        }

        .voice-status {
            text-align: center;
            font-size: 1.2rem;
            color: var(--text-muted);
            margin-bottom: 2rem;
            font-weight: 500;
        }

        .chat-history {
            max-height: 400px;
            overflow-y: auto;
            margin-bottom: 2rem;
            padding: 1.5rem;
            background: var(--bg-card);
            border-radius: 20px;
            border: 1px solid var(--border);
        }

        .chat-message {
            margin-bottom: 1.5rem;
            padding: 1.2rem 1.5rem;
            border-radius: 20px;
            animation: messageSlide 0.4s ease;
        }

        @keyframes messageSlide {
            from {
                opacity: 0;
                transform: translateX(-30px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        .chat-message.user {
            background: linear-gradient(135deg, var(--primary), var(--accent));
            color: var(--bg-dark);
            margin-left: 15%;
            border-radius: 20px 20px 5px 20px;
        }

        .chat-message.assistant {
            background: var(--glass-bg);
            border: 1px solid var(--border);
            margin-right: 15%;
            border-radius: 20px 20px 20px 5px;
        }

        .chat-message strong {
            display: block;
            margin-bottom: 0.5rem;
            font-size: 0.9rem;
            opacity: 0.8;
        }

        .voice-input-area {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
        }

        .voice-text-input {
            flex: 1;
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 50px;
            padding: 1rem 1.5rem;
            color: var(--text);
            font-size: 1rem;
            outline: none;
            transition: all 0.3s ease;
        }

        .voice-text-input:focus {
            border-color: var(--primary);
            box-shadow: 0 0 0 3px var(--primary-glow);
        }

        .send-btn {
            background: linear-gradient(135deg, var(--primary), var(--accent));
            color: var(--bg-dark);
            border: none;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            cursor: pointer;
            font-size: 1.3rem;
            transition: all 0.3s ease;
        }

        .send-btn:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 20px var(--primary-glow);
        }

        .voice-tips {
            margin-top: 2rem;
            padding: 1.5rem;
            background: var(--bg-card);
            border-radius: 20px;
            border: 1px solid var(--border);
        }

        .voice-tips h4 {
            color: var(--primary);
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .voice-tips ul {
            list-style: none;
            color: var(--text-muted);
            line-height: 2;
        }

        .voice-tips li::before {
            content: 'üí¨ ';
            margin-right: 0.5rem;
        }

        /* Skills Section with Radar Chart */
        .skills-widget {
            margin-top: 5rem;
            background: var(--glass-bg);
            backdrop-filter: blur(20px);
            border: 1px solid var(--glass-border);
            border-radius: 30px;
            padding: 3rem;
        }

        .skills-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
            margin-top: 2rem;
        }

        .skill-category {
            padding: 2rem;
            background: var(--bg-card);
            border-radius: 20px;
            border: 1px solid var(--border);
        }

        .skill-category h4 {
            color: var(--primary);
            margin-bottom: 1.5rem;
            font-size: 1.3rem;
        }

        .skill-item {
            margin-bottom: 1.5rem;
        }

        .skill-header {
            display: flex;
            justify-content: space-between;
            margin-bottom: 0.5rem;
        }

        .skill-name {
            font-weight: 600;
            color: var(--text);
        }

        .skill-level {
            color: var(--primary);
            font-weight: 600;
        }

        .skill-bar {
            height: 8px;
            background: var(--bg-card);
            border-radius: 10px;
            overflow: hidden;
        }

        .skill-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--primary), var(--accent));
            border-radius: 10px;
            width: 0;
            transition: width 1.5s cubic-bezier(0.4, 0, 0.2, 1);
        }

        .skill-fill.animate {
            width: var(--skill-width);
        }

        /* Responsive Design */
        @media (max-width: 1024px) {
            .bento-large, .bento-medium, .bento-small {
                grid-column: span 12;
            }
        }

        @media (max-width: 768px) {
            nav {
                width: 90%;
                padding: 0.8rem 1.5rem;
            }

            .nav-content {
                gap: 1.5rem;
            }

            .nav-links {
                display: none;
            }

            .hero-content {
                padding: 3rem 2rem;
            }

            .cta-group {
                flex-direction: column;
            }

            .btn-primary, .btn-secondary {
                width: 100%;
                text-align: center;
            }

            .chat-message.user {
                margin-left: 5%;
            }

            .chat-message.assistant {
                margin-right: 5%;
            }

            .skills-grid {
                grid-template-columns: 1fr;
            }
        }

        /* Scrollbar Styling */
        ::-webkit-scrollbar {
            width: 10px;
        }

        ::-webkit-scrollbar-track {
            background: var(--bg-dark);
        }

        ::-webkit-scrollbar-thumb {
            background: linear-gradient(180deg, var(--primary), var(--accent));
            border-radius: 10px;
        }

        ::-webkit-scrollbar-thumb:hover {
            background: var(--primary);
        }

        .hidden { display: none !important; }

        /* Loading Animation */
        .loading-dots {
            display: inline-flex;
            gap: 0.3rem;
        }

        .loading-dots span {
            width: 8px;
            height: 8px;
            background: var(--primary);
            border-radius: 50%;
            animation: loadingBounce 1.4s ease-in-out infinite;
        }

        .loading-dots span:nth-child(1) { animation-delay: 0s; }
        .loading-dots span:nth-child(2) { animation-delay: 0.2s; }
        .loading-dots span:nth-child(3) { animation-delay: 0.4s; }

        @keyframes loadingBounce {
            0%, 80%, 100% { transform: scale(0); opacity: 0.5; }
            40% { transform: scale(1); opacity: 1; }
        }
    </style>
</head>
<body>
    <div class="bg-mesh"></div>

    <!-- Navigation -->
    <nav>
        <div class="nav-content">
            <div class="logo">YS</div>
            <ul class="nav-links">
                <li><a href="#" onclick="showSection('landing')">Home</a></li>
                <li><a href="#" onclick="showSection('dashboard')">Projects</a></li>
                <li><a href="#" onclick="showSection('voice')">AI Assistant</a></li>
            </ul>
            <button class="theme-toggle-btn" onclick="toggleTheme()" id="themeBtn">üåô</button>
        </div>
    </nav>

    <!-- Landing Section -->
    <section class="landing active" id="landing">
        <div class="floating-icons">
            <div class="tech-icon">üêç</div>
            <div class="tech-icon">ü§ñ</div>
            <div class="tech-icon">‚öõÔ∏è</div>
            <div class="tech-icon">üî•</div>
            <div class="tech-icon">‚òÅÔ∏è</div>
            <div class="tech-icon">üéØ</div>
        </div>

        <div class="hero-3d-card">
            <div class="card-inner" id="heroCard">
                <div class="hero-content">
                    <span class="hero-badge">üöÄ AI Engineer & Full-Stack Developer</span>
                    <h1 class="hero-title">Yash Shah</h1>
                    <div class="typing-container">
                        <span class="hero-subtitle" id="typingText"></span>
                        <span class="typing-cursor"></span>
                    </div>
                    <p class="hero-description">
                        Specializing in conversational AI, voice-enabled applications, and production-grade ML systems. 
                        Built privacy-first voice assistants with local LLM inference and real-time dialogue management.
                    </p>
                    <div class="cta-group">
                        <button class="btn-primary" onclick="showSection('dashboard')">View Projects</button>
                        <button class="btn-secondary" onclick="showSection('voice')">Talk to AI Assistant</button>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Dashboard Section -->
    <section class="dashboard" id="dashboard">
        <div class="section-header">
            <h2 class="section-title">Featured Projects</h2>
            <p class="section-subtitle">Production AI systems and full-stack applications</p>
        </div>

        <div class="bento-grid" id="projectsGrid"></div>

        <div class="skills-widget">
            <h3 class="section-title" style="font-size: 2.5rem;">Technical Expertise</h3>
            <div class="skills-grid" id="skillsGrid"></div>
        </div>
    </section>

    <!-- Voice Assistant Section -->
    <section class="voice-section" id="voice">
        <div class="section-header">
            <h2 class="section-title">AI Voice Assistant</h2>
            <p class="section-subtitle">Ask me about my experience, projects, and technical skills</p>
        </div>

        <div class="voice-container">
            <div class="voice-visualizer">
                <div class="voice-orb" id="voiceOrb" onclick="toggleVoice()">
                    <div class="voice-waves"></div>
                    <div class="voice-waves"></div>
                    <div class="voice-waves"></div>
                    <span class="voice-icon">üéôÔ∏è</span>
                </div>
            </div>

            <p class="voice-status" id="voiceStatus">Click microphone to speak or type below</p>

            <div class="chat-history" id="chatHistory"></div>

            <div class="voice-input-area">
                <input 
                    type="text" 
                    class="voice-text-input" 
                    id="textInput" 
                    placeholder="Type your question here..."
                    onkeypress="if(event.key==='Enter') sendTextMessage()"
                >
                <button class="send-btn" onclick="sendTextMessage()">‚û§</button>
            </div>

            <div class="voice-tips">
                <h4>üí° Try asking:</h4>
                <ul>
                    <li>"Tell me about the Tara voice assistant project"</li>
                    <li>"What experience do you have with LLMs and fine-tuning?"</li>
                    <li>"Explain your work at YogoSocial"</li>
                    <li>"What technologies do you specialize in?"</li>
                    <li>"Tell me about your education and certifications"</li>
                    <li>"How did you implement wake word detection?"</li>
                </ul>
            </div>
        </div>
    </section>

    <script>
        // Data
        const projects = [
            {
                id: 1,
                icon: 'üéôÔ∏è',
                title: 'Tara: Privacy-First Voice Assistant',
                tag: 'AI/ML',
                description: 'Fully offline Windows service with local speech recognition (Vosk ASR) and local LLM inference (7B models, 4-bit quantization). Features custom wake word detection with 95% accuracy and RAG-based file indexing.',
                tech: ['Python', 'Vosk', 'LLM', 'RAG', 'Windows Service'],
                size: 'large'
            },
            {
                id: 2,
                icon: 'üè•',
                title: 'Pandora\'s Box: Health AI Chatbot',
                tag: 'Full-Stack',
                description: 'Conversational health AI with multi-persona response system using prompt engineering. Next.js/Supabase stack with authentication and personalized conversation history.',
                tech: ['Next.js', 'Supabase', 'LLM', 'TypeScript'],
                link: 'https://github.com/ykshah1309/pandoras-box',
                size: 'large'
            },
            {
                id: 3,
                icon: 'üíº',
                title: 'YogoSocial B2B Analytics',
                tag: 'Full-Stack',
                description: 'AWS Amplify Gen2 backend with TypeScript, DynamoDB, and secure Lambda functions for multi-tenant SaaS. React dashboard with real-time customer segmentation.',
                tech: ['AWS', 'React', 'TypeScript', 'DynamoDB', 'Lambda'],
                size: 'medium'
            },
            {
                id: 4,
                icon: '‚ö°',
                title: 'StarCoder2 Fine-tuning',
                tag: 'AI/ML',
                description: 'Fine-tuned StarCoder2-15B on 45K C# functions using LoRA, achieving 18% improvement in code completion. Built preprocessing pipeline with Tree-sitter AST parsing.',
                tech: ['PyTorch', 'LoRA', 'HuggingFace', 'Tree-sitter'],
                link: 'https://github.com/ykshah1309',
                size: 'medium'
            },
            {
                id: 5,
                icon: 'üìä',
                title: 'ML Sentiment Analysis',
                tag: 'AI/ML',
                description: 'End-to-end ML pipeline for sentiment analysis on 50K+ documents with TF-IDF and word2vec, achieving 89% F1-score.',
                tech: ['Python', 'TF-IDF', 'SVM', 'NLP'],
                size: 'small'
            },
            {
                id: 6,
                icon: 'üé®',
                title: '3D-AR Portfolio',
                tag: 'Creative',
                description: 'Interactive AR portfolio and business card using Zapworks and Unity with immersive 3D visualizations.',
                tech: ['Unity', 'Zapworks', 'AR'],
                link: 'https://github.com/ykshah1309/3D-AR-portfolio',
                size: 'small'
            }
        ];

        const skills = {
            'Conversational AI': [
                { name: 'Dialogue State Tracking', level: 95 },
                { name: 'Speech Recognition (Vosk, Whisper)', level: 92 },
                { name: 'Wake Word Detection', level: 90 },
                { name: 'Context Management', level: 88 }
            ],
            'ML Engineering': [
                { name: 'LLMs (LLaMA, Qwen, GPT)', level: 93 },
                { name: 'Fine-tuning (LoRA, QLoRA)', level: 90 },
                { name: 'RAG & Vector DBs', level: 87 },
                { name: 'PyTorch & Transformers', level: 91 }
            ],
            'Full-Stack Development': [
                { name: 'React & Next.js', level: 92 },
                { name: 'TypeScript & Python', level: 95 },
                { name: 'FastAPI & Node.js', level: 88 },
                { name: 'PostgreSQL & DynamoDB', level: 85 }
            ],
            'Infrastructure & Tools': [
                { name: 'AWS (Amplify, Lambda, S3)', level: 87 },
                { name: 'Docker & Containerization', level: 83 },
                { name: 'Git & CI/CD', level: 90 },
                { name: 'Linux/Bash', level: 85 }
            ]
        };

        const typingRoles = [
            'AI Engineer',
            'Voice Assistant Developer',
            'ML Engineer',
            'Full-Stack Developer',
            'Conversational AI Specialist'
        ];

        // Enhanced Knowledge Base from Resume
        const knowledgeBase = {
            profile: "AI Engineer specializing in conversational systems and voice-enabled applications. Built production voice assistant with local LLM inference, speech recognition, and real-time dialogue management. Passionate about creating AI systems that solve real problems through natural language interaction.",
            
            education: {
                masters: "Master of Science in Data Science (Computational Track) from New Jersey Institute of Technology, CGPA: 3.75/4.0, Expected Dec 2025",
                bachelors: "Bachelor of Technology in Computer Engineering with Minor in Data Science from SVKM's Dwarkadas J. Sanghvi College of Engineering, Mumbai, GPA: 3.73/4.0, Graduated Jul 2024"
            },
            
            experience: {
                current: {
                    role: "AI-Full Stack Engineer at YogoSocial ‚Äì Agenticue by Juegoes, Oct 2025 ‚Äì Present",
                    details: "Building B2B analytics platform at early-stage startup. Architected AWS Amplify Gen2 backend with TypeScript, DynamoDB, and secure Lambda functions for multi-tenant SaaS infrastructure. Developed React analytics dashboard with real-time customer segmentation and engagement tracking. Researching conversational LLM integration patterns for real-time customer interactions."
                },
                internship: {
                    role: "AI/ML Intern at Verzeo/IBM, Mumbai, Apr 2022 ‚Äì Sep 2022",
                    details: "Developed end-to-end ML pipeline for sentiment analysis on 50K+ documents, implementing TF-IDF and word2vec with SVM classifiers achieving 89% F1-score. Built data preprocessing workflows with automated feature extraction."
                }
            },
            
            projects: {
                tara: {
                    name: "Tara: Privacy-First Voice Assistant for Personal Knowledge Management",
                    date: "Oct 2025",
                    description: "Built fully offline Windows service with local speech recognition (Vosk ASR) and local LLM inference (7B models, 4-bit quantization) to address privacy concerns with cloud-based voice assistants.",
                    technical: "Implemented custom wake word detection with adaptive threshold tuning, achieving 95% detection rate while reducing false positives from 12% to 0.3%. Integrated RAG-based file indexing for context-aware responses with less than 2s latency. System runs 24/7 on personal machine with sub-2GB memory footprint.",
                    impact: "Demonstrated viable privacy-preserving conversational AI on consumer hardware."
                },
                pandoras: {
                    name: "Pandora's Box: Conversational Health AI with Empathetic Response Generation",
                    description: "Developed full-stack women's health chatbot (Next.js/Supabase) with multi-persona response system using prompt engineering, focusing on emotionally supportive conversations for sensitive health topics.",
                    technical: "Designed conversation flows prioritizing user safety with content filtering for medically appropriate responses. Integrated authentication and conversation history for personalized long-term interactions."
                },
                starcoder: {
                    name: "StarCoder2 Fine-tuning for Domain-Specific Code Generation",
                    date: "Jan ‚Äì May 2025",
                    description: "Fine-tuned StarCoder2-15B on 45K C# functions using parameter-efficient LoRA (rank-16), achieving 18% improvement in code completion accuracy over base model on HumanEval-style benchmarks.",
                    technical: "Built preprocessing pipeline with Tree-sitter AST parsing and MinHash LSH deduplication (98% duplicate removal). Explored trade-offs between model size, training time, and task performance."
                }
            },
            
            skills: {
                conversational_ai: "Dialogue state tracking, intent classification, speech recognition (Vosk, Whisper), TTS (pyttsx3), wake word detection, context management",
                ml_engineering: "LLMs (LLaMA, Qwen, GPT), fine-tuning (LoRA, QLoRA, PEFT), RAG, PyTorch, Transformers, Hugging Face, vLLM",
                fullstack: "React, Next.js, Node.js, TypeScript, Python, FastAPI, WebSocket, Supabase, PostgreSQL, DynamoDB",
                infrastructure: "AWS (Amplify, Lambda, S3, EC2), Docker, Vector DBs (Pinecone, ChromaDB), Git, Linux/Bash"
            },
            
            certifications: "IBM Machine Learning with Python, HackerRank SQL (Advanced), Audio-Based Facial Expression Generation on AR Applications (IEEE 2023 publication)",
            
            contact: {
                email: "ykshah1309@gmail.com",
                linkedin: "linkedin.com/in/ykshah1309",
                github: "github.com/ykshah1309",
                phone: "+1 (862) 230-8196"
            }
        };

        let currentTheme = 'dark';
        let currentRoleIndex = 0;
        let currentCharIndex = 0;
        let isDeleting = false;
        let isListening = false;
        let recognition, synthesis;

        // Initialize
        function init() {
            createParticles();
            renderProjects();
            renderSkills();
            startTypingAnimation();
            initVoiceRecognition();
            add3DCardEffect();
        }

        // Typing Animation
        function startTypingAnimation() {
            const element = document.getElementById('typingText');
            const currentRole = typingRoles[currentRoleIndex];

            if (!isDeleting && currentCharIndex < currentRole.length) {
                element.textContent = currentRole.substring(0, currentCharIndex + 1);
                currentCharIndex++;
                setTimeout(startTypingAnimation, 100);
            } else if (isDeleting && currentCharIndex > 0) {
                element.textContent = currentRole.substring(0, currentCharIndex - 1);
                currentCharIndex--;
                setTimeout(startTypingAnimation, 50);
            } else if (!isDeleting && currentCharIndex === currentRole.length) {
                setTimeout(() => { isDeleting = true; startTypingAnimation(); }, 2000);
            } else if (isDeleting && currentCharIndex === 0) {
                isDeleting = false;
                currentRoleIndex = (currentRoleIndex + 1) % typingRoles.length;
                setTimeout(startTypingAnimation, 500);
            }
        }

        // 3D Card Effect
        function add3DCardEffect() {
            const card = document.getElementById('heroCard');
            const hero = document.querySelector('.landing');
            
            hero.addEventListener('mousemove', (e) => {
                const rect = hero.getBoundingClientRect();
                const x = e.clientX - rect.left;
                const y = e.clientY - rect.top;
                const centerX = rect.width / 2;
                const centerY = rect.height / 2;
                const rotateX = (y - centerY) / 30;
                const rotateY = (centerX - x) / 30;
                
                card.style.transform = `perspective(1000px) rotateX(${rotateX}deg) rotateY(${rotateY}deg)`;
            });
            
            hero.addEventListener('mouseleave', () => {
                card.style.transform = 'perspective(1000px) rotateX(0) rotateY(0)';
            });
        }

        // Theme Toggle
        function toggleTheme() {
            currentTheme = currentTheme === 'dark' ? 'light' : 'dark';
            document.documentElement.setAttribute('data-theme', currentTheme);
            document.getElementById('themeBtn').textContent = currentTheme === 'dark' ? 'üåô' : '‚òÄÔ∏è';
        }

        // Navigation
        function showSection(section) {
            ['landing', 'dashboard', 'voice'].forEach(s => {
                document.getElementById(s).classList.remove('active');
            });
            document.getElementById(section).classList.add('active');
            
            if (section === 'dashboard') {
                animateSkills();
            }
        }

        // Render Projects
        function renderProjects() {
            const grid = document.getElementById('projectsGrid');
            grid.innerHTML = projects.map(project => `
                <div class="bento-item bento-${project.size}">
                    <div class="project-icon">${project.icon}</div>
                    <span class="project-tag">${project.tag}</span>
                    <h3 class="project-title">${project.title}</h3>
                    <p class="project-description">${project.description}</p>
                    <div class="project-tech-stack">
                        ${project.tech.map(tech => `<span class="tech-badge">${tech}</span>`).join('')}
                    </div>
                    ${project.link ? `<a href="${project.link}" target="_blank" class="project-link">View Project ‚Üí</a>` : ''}
                </div>
            `).join('');

            // Mouse tracking
            document.querySelectorAll('.bento-item').forEach(item => {
                item.addEventListener('mousemove', (e) => {
                    const rect = item.getBoundingClientRect();
                    const x = ((e.clientX - rect.left) / rect.width) * 100;
                    const y = ((e.clientY - rect.top) / rect.height) * 100;
                    item.style.setProperty('--mouse-x', x + '%');
                    item.style.setProperty('--mouse-y', y + '%');
                });
            });
        }

        // Render Skills
        function renderSkills() {
            const grid = document.getElementById('skillsGrid');
            grid.innerHTML = Object.entries(skills).map(([category, skillList]) => `
                <div class="skill-category">
                    <h4>${category}</h4>
                    ${skillList.map(skill => `
                        <div class="skill-item">
                            <div class="skill-header">
                                <span class="skill-name">${skill.name}</span>
                                <span class="skill-level">${skill.level}%</span>
                            </div>
                            <div class="skill-bar">
                                <div class="skill-fill" style="--skill-width: ${skill.level}%"></div>
                            </div>
                        </div>
                    `).join('')}
                </div>
            `).join('');
        }

        function animateSkills() {
            document.querySelectorAll('.skill-fill').forEach((fill, index) => {
                setTimeout(() => {
                    fill.classList.add('animate');
                }, index * 100);
            });
        }

        // Voice Assistant
        function initVoiceRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    handleUserInput(transcript, true);
                };

                recognition.onerror = (event) => {
                    console.error('Speech recognition error:', event.error);
                    updateVoiceStatus('Error: Please try again');
                    stopListening();
                };

                recognition.onend = () => stopListening();

                synthesis = window.speechSynthesis;
            }
        }

        function toggleVoice() {
            if (!recognition) {
                alert('Speech recognition not supported. Please type your question instead.');
                return;
            }
            
            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        }

        function startListening() {
            isListening = true;
            document.getElementById('voiceOrb').classList.add('listening');
            updateVoiceStatus('üé§ Listening... Speak now');
            recognition.start();
        }

        function stopListening() {
            isListening = false;
            document.getElementById('voiceOrb').classList.remove('listening');
            updateVoiceStatus('Click microphone to speak or type below');
            if (recognition) recognition.stop();
        }

        function updateVoiceStatus(status) {
            document.getElementById('voiceStatus').textContent = status;
        }

        function sendTextMessage() {
            const input = document.getElementById('textInput');
            const text = input.value.trim();
            if (text) {
                handleUserInput(text, false);
                input.value = '';
            }
        }

        function handleUserInput(input, isVoice) {
            addChatMessage(input, true);
            updateVoiceStatus('ü§î Thinking...');
            
            setTimeout(() => {
                const response = generateAdvancedResponse(input.toLowerCase());
                addChatMessage(response, false);
                
                if (isVoice && synthesis) {
                    speak(response);
                } else {
                    updateVoiceStatus('Click microphone to speak or type below');
                }
            }, 800);
        }

        function addChatMessage(text, isUser) {
            const chatHistory = document.getElementById('chatHistory');
            const message = document.createElement('div');
            message.className = `chat-message ${isUser ? 'user' : 'assistant'}`;
            message.innerHTML = `<strong>${isUser ? 'You' : 'AI Assistant'}</strong>${text}`;
            chatHistory.appendChild(message);
            chatHistory.scrollTop = chatHistory.scrollHeight;
        }

        function speak(text) {
            if (synthesis.speaking) synthesis.cancel();
            
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 0.9;
            utterance.pitch = 1;
            utterance.volume = 1;
            
            utterance.onstart = () => updateVoiceStatus('üîä Speaking...');
            utterance.onend = () => updateVoiceStatus('Click microphone to speak or type below');
            
            synthesis.speak(utterance);
        }

        function generateAdvancedResponse(input) {
            // Tara Project
            if ((input.includes('tara') || input.includes('voice assistant')) && (input.includes('project') || input.includes('tell') || input.includes('explain') || input.includes('about'))) {
                return `The Tara project is my privacy-first voice assistant built in October 2025. It's a fully offline Windows service featuring local speech recognition using Vosk ASR and local LLM inference with 7B models using 4-bit quantization. Key achievements include: custom wake word detection with 95% accuracy (reduced false positives from 12% to 0.3%), RAG-based file indexing for context-aware responses with under 2 second latency, and a sub-2GB memory footprint that runs 24/7 on consumer hardware. This project demonstrates viable privacy-preserving conversational AI without cloud dependencies.`;
            }

            if (input.includes('wake word') && (input.includes('detection') || input.includes('implement') || input.includes('how') || input.includes('work'))) {
                return `I implemented wake word detection in Tara using adaptive threshold tuning techniques. The system achieved a 95% detection rate while dramatically reducing false positives from 12% to just 0.3%. This involved analyzing audio patterns, setting dynamic confidence thresholds, and continuously tuning the model based on real-world performance data. The wake word system runs continuously without significant CPU overhead.`;
            }

            // Pandora's Box Project
            if ((input.includes('pandora') || input.includes('health')) && (input.includes('chatbot') || input.includes('project'))) {
                return `Pandora's Box is a conversational health AI chatbot I developed for women's health topics. Built with Next.js and Supabase, it features a multi-persona response system using advanced prompt engineering. The system focuses on emotionally supportive conversations for sensitive health topics, with content filtering for medically appropriate responses. It includes authentication and maintains conversation history for personalized long-term interactions.`;
            }

            // StarCoder Fine-tuning
            if ((input.includes('starcoder') || input.includes('code generation')) || (input.includes('fine-tun') && input.includes('lora'))) {
                return `I fine-tuned StarCoder2-15B on 45,000 C# functions using parameter-efficient LoRA with rank-16, achieving an 18% improvement in code completion accuracy over the base model on HumanEval-style benchmarks. I built a preprocessing pipeline with Tree-sitter AST parsing for syntax analysis and MinHash LSH deduplication that removed 98% of duplicates. This project involved exploring critical trade-offs between model size, training time, and task-specific performance.`;
            }

            // Work Experience - YogoSocial
            if ((input.includes('yogo') || input.includes('current') || input.includes('job')) && (input.includes('work') || input.includes('role') || input.includes('doing'))) {
                return `I'm currently working as an AI-Full Stack Engineer at YogoSocial (Agenticue by Juegoes) since October 2025. I'm building a B2B analytics platform at this early-stage startup. I architected the AWS Amplify Gen2 backend using TypeScript, DynamoDB, and secure Lambda functions for multi-tenant SaaS infrastructure. I also developed the React analytics dashboard with real-time customer segmentation and engagement tracking, and I'm researching conversational LLM integration patterns for real-time customer interactions.`;
            }

            if (input.includes('aws') || input.includes('amplify') || input.includes('lambda')) {
                return `I have extensive AWS experience from my current role at YogoSocial where I architected an AWS Amplify Gen2 backend. I work with DynamoDB for database management, Lambda functions for serverless compute, and implement secure multi-tenant SaaS infrastructure. I'm also experienced with S3 for storage and EC2 for compute instances. I focus on building scalable, production-ready cloud architectures.`;
            }

            // ML & LLM Experience
            if ((input.includes('llm') || input.includes('language model')) && (input.includes('experience') || input.includes('work') || input.includes('fine-tun'))) {
                return `I have deep experience with LLMs including LLaMA, Qwen, and GPT models. I've fine-tuned models using parameter-efficient techniques like LoRA, QLoRA, and PEFT. In the Tara project, I implemented local LLM inference with 7B models using 4-bit quantization for efficient on-device performance. I've also worked extensively with RAG (Retrieval-Augmented Generation) systems, vector databases like Pinecone and ChromaDB, and frameworks like PyTorch, Transformers, and Hugging Face.`;
            }

            if (input.includes('rag') || input.includes('retrieval')) {
                return `I implemented RAG (Retrieval-Augmented Generation) in my Tara voice assistant project to enable context-aware responses. The system performs file indexing and retrieves relevant information with under 2 second latency. I use vector databases to store embeddings and retrieve contextually relevant information that augments the LLM's responses. This allows the assistant to answer questions about local documents and personal knowledge bases accurately.`;
            }

            // Education
            if (input.includes('education') || input.includes('degree') || input.includes('university') || input.includes('study')) {
                return `I'm pursuing a Master of Science in Data Science (Computational Track) at New Jersey Institute of Technology with a CGPA of 3.75/4.0, expected to graduate in December 2025. I completed my Bachelor of Technology in Computer Engineering with a Minor in Data Science from SVKM's Dwarkadas J. Sanghvi College of Engineering in Mumbai with a GPA of 3.73/4.0, graduating in July 2024.`;
            }

            // Technical Skills
            if (input.includes('skills') || input.includes('technologies') || input.includes('tools') || input.includes('stack')) {
                if (input.includes('conversational') || input.includes('voice') || input.includes('speech')) {
                    return `My conversational AI skills include: dialogue state tracking, intent classification, speech recognition with Vosk and Whisper, text-to-speech with pyttsx3, custom wake word detection, and context management. I've built production voice assistants with these technologies.`;
                }
                return `My technical expertise spans four main areas: (1) Conversational AI - dialogue state tracking, speech recognition with Vosk and Whisper, wake word detection, and context management. (2) ML Engineering - LLMs like LLaMA and Qwen, fine-tuning with LoRA and QLoRA, RAG systems, PyTorch, and Hugging Face. (3) Full-Stack Development - React, Next.js, TypeScript, Python, FastAPI, Supabase, and PostgreSQL. (4) Infrastructure - AWS services, Docker, vector databases, Git, and Linux.`;
            }

            if (input.includes('python') || input.includes('programming language')) {
                return `Python is my primary language for AI/ML work and backend development. I've used it extensively for building ML pipelines, implementing voice assistants with Vosk, fine-tuning LLMs with PyTorch, developing FastAPI services, and creating automation systems. I'm highly proficient in Python libraries like Transformers, NumPy, Pandas, and scikit-learn.`;
            }

            if (input.includes('react') || input.includes('next') || input.includes('frontend')) {
                return `I'm highly skilled in modern frontend development with React and Next.js. At YogoSocial, I built React analytics dashboards with real-time customer segmentation. In the Pandora's Box project, I used Next.js with TypeScript for the full-stack health chatbot. I'm experienced with state management, hooks, server-side rendering, and building responsive, production-grade UIs.`;
            }

            // Certifications
            if (input.includes('certification') || input.includes('publication')) {
                return `I hold certifications in IBM Machine Learning with Python and HackerRank SQL (Advanced). I also co-authored a research paper on "Audio-Based Facial Expression Generation on AR Applications" published in IEEE 2023, which explored innovative AR interactions using audio signals.`;
            }

            // Contact & Availability
            if (input.includes('contact') || input.includes('email') || input.includes('reach') || input.includes('hire')) {
                return `You can reach me at ykshah1309@gmail.com or call me at +1 (862) 230-8196. I'm also active on LinkedIn at linkedin.com/in/ykshah1309 and GitHub at github.com/ykshah1309. I'm currently seeking opportunities to apply my ML engineering and full-stack development skills to challenging AI problems.`;
            }

            // Internship Experience
            if (input.includes('internship') || input.includes('verzeo') || input.includes('ibm')) {
                return `I worked as an AI/ML Intern at Verzeo/IBM in Mumbai from April to September 2022. I developed an end-to-end ML pipeline for sentiment analysis on over 50,000 documents, implementing TF-IDF and word2vec with SVM classifiers that achieved an 89% F1-score. I also built data preprocessing workflows with automated feature extraction to improve model training efficiency and reproducibility.`;
            }

            // Default comprehensive response
            return `I'm an AI Engineer specializing in conversational systems and voice-enabled applications. I've built production voice assistants with local LLM inference, speech recognition, and real-time dialogue management. Currently, I'm working at YogoSocial building B2B analytics platforms with AWS and React. My technical expertise includes conversational AI, LLM fine-tuning with LoRA, RAG systems, and full-stack development with React and Next.js. Feel free to ask me about any specific project, technology, or experience!`;
        }

        function createParticles() {
            // Minimal particle implementation
        }

        // Initialize on load
        window.addEventListener('DOMContentLoaded', init);
    </script>
</body>
</html>
